{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition des transformations à appliquer aux images\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convertit les images en tenseurs PyTorch de dimensions [channels, height, width]\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalisation avec la moyenne et l'écart-type de MNIST\n",
    "])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "val_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vérifier la dispersion dans chaque classe\n",
    "rajouter un split test pour valider la recherche d'hyperparamètre pour valider les hyperparamètres : tailles des NN, dropout\n",
    "utiliser optuna\n",
    "augmentation des données\n",
    "80/10/10 avec l'équilibre entre les classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille des images : torch.Size([64, 1, 28, 28])\n",
      "Taille des labels : torch.Size([64])\n",
      "Images min/max : -0.4242129623889923/2.821486711502075\n",
      "Labels uniques : tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = next(dataiter)\n",
    "print(f'Taille des images : {images.shape}')  # Doit être [64, 1, 28, 28]\n",
    "print(f'Taille des labels : {labels.shape}')   # Doit être [64]\n",
    "\n",
    "print(f'Images min/max : {images.min()}/{images.max()}')  # Doit être entre 0.0 et 1.0\n",
    "print(f'Labels uniques : {labels.unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlexibleCNN(nn.Module):\n",
    "    def __init__(self, conv_layers_params, dense_layers_sizes, dropout_conv=0.0, dropout_dense=0.0):\n",
    "        \"\"\"\n",
    "        CNN flexible avec ajout de dropout, où les paramètres des couches convolutionnelles et des couches denses peuvent être spécifiés.\n",
    "\n",
    "        :param conv_layers_params: Liste de dictionnaires contenant les paramètres pour chaque couche convolutionnelle.\n",
    "                                   Chaque dictionnaire doit avoir les clés 'out_channels', 'kernel_size', 'stride', et 'padding'.\n",
    "        :param dense_layers_sizes: Liste contenant les tailles des couches denses après les convolutions.\n",
    "                                   Par exemple, [128, 64] signifie deux couches denses avec 128 et 64 neurones respectivement.\n",
    "        :param dropout_conv: Probabilité de dropout après les couches convolutionnelles (par défaut 0.0, pas de dropout).\n",
    "        :param dropout_dense: Probabilité de dropout après les couches denses (par défaut 0.0, pas de dropout).\n",
    "        \"\"\"\n",
    "        super(FlexibleCNN, self).__init__()\n",
    "        self.conv_layers = nn.Sequential()\n",
    "        in_channels = 1  # Pour MNIST, les images ont un canal en entrée\n",
    "        for idx, conv_params in enumerate(conv_layers_params):\n",
    "            # Création dynamique des couches convolutionnelles\n",
    "            self.conv_layers.add_module(\n",
    "                f'conv_{idx}',\n",
    "                nn.Conv2d(\n",
    "                    in_channels,\n",
    "                    conv_params['out_channels'],\n",
    "                    kernel_size=conv_params.get('kernel_size', 3),\n",
    "                    stride=conv_params.get('stride', 1),\n",
    "                    padding=conv_params.get('padding', 1)\n",
    "                )\n",
    "            )\n",
    "            self.conv_layers.add_module(f'relu_{idx}', nn.ReLU())\n",
    "            self.conv_layers.add_module(f'pool_{idx}', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            if dropout_conv > 0.0:\n",
    "                self.conv_layers.add_module(f'dropout_conv_{idx}', nn.Dropout2d(p=dropout_conv))\n",
    "            in_channels = conv_params['out_channels']\n",
    "\n",
    "        # Calcul de la taille après les couches convolutionnelles pour aplatir correctement\n",
    "        self.flatten_size = self._get_flatten_size()\n",
    "\n",
    "        # Création dynamique des couches denses\n",
    "        self.dense_layers = nn.Sequential()\n",
    "        input_size = self.flatten_size\n",
    "        for idx, size in enumerate(dense_layers_sizes):\n",
    "            self.dense_layers.add_module(f'fc_{idx}', nn.Linear(input_size, size))\n",
    "            self.dense_layers.add_module(f'relu_fc_{idx}', nn.ReLU())\n",
    "            if dropout_dense > 0.0:\n",
    "                self.dense_layers.add_module(f'dropout_dense_{idx}', nn.Dropout(p=dropout_dense))\n",
    "            input_size = size\n",
    "        # Dernière couche pour la classification\n",
    "        self.dense_layers.add_module('output', nn.Linear(input_size, 10))  # 10 classes pour MNIST\n",
    "\n",
    "    def _get_flatten_size(self):\n",
    "        # Méthode pour calculer la taille du tenseur après les convolutions\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 1, 28, 28)  # Taille d'une image MNIST\n",
    "            x = self.conv_layers(dummy_input)\n",
    "            flatten_size = x.view(1, -1).size(1)\n",
    "        return flatten_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(-1, self.flatten_size)  # Aplatir pour les couches denses\n",
    "        x = self.dense_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramètres d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FlexibleCNN(\n",
      "  (conv_layers): Sequential(\n",
      "    (conv_0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu_0): ReLU()\n",
      "    (pool_0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (conv_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (relu_1): ReLU()\n",
      "    (pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (dense_layers): Sequential(\n",
      "    (fc_0): Linear(in_features=3136, out_features=128, bias=True)\n",
      "    (relu_fc_0): ReLU()\n",
      "    (fc_1): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (relu_fc_1): ReLU()\n",
      "    (output): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Taille de la sortie du modèle : torch.Size([64, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\emac\\Documents\\M2\\DeepLearning\\dl_venv\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Exemple de paramètres pour un CNN flexible\n",
    "conv_layers_params = [\n",
    "    {'out_channels': 32, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    {'out_channels': 64, 'kernel_size': 3, 'stride': 1, 'padding': 1},\n",
    "    # Vous pouvez ajouter autant de couches que vous le souhaitez\n",
    "]\n",
    "dense_layers_sizes = [128, 64]  # Tailles des couches denses\n",
    "\n",
    "# Instanciation du modèle flexible\n",
    "model = FlexibleCNN(conv_layers_params, dense_layers_sizes)\n",
    "\n",
    "# Vérification du modèle\n",
    "print(model)\n",
    "\n",
    "# Instanciation de la fonction de perte et de l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n",
    "\n",
    "# Test du modèle avec un batch d'images\n",
    "output = model(images)\n",
    "print(f'Taille de la sortie du modèle : {output.shape}')  # Doit être [64, 10]\n",
    "\n",
    "# Boucle d'entraînement\n",
    "num_epochs = 100\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.1626, Train Accuracy: 94.95%, Validation Loss: 0.0527, Validation Accuracy: 98.34%\n",
      "Meilleur modèle sauvegardé avec une perte de validation de 0.0527\n",
      "Epoch 2/100, Train Loss: 0.0477, Train Accuracy: 98.51%, Validation Loss: 0.0453, Validation Accuracy: 98.54%\n",
      "Meilleur modèle sauvegardé avec une perte de validation de 0.0453\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)  # images de taille [batch_size, 1, 28, 28]\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        # Calcul de l'accuracy sur l'ensemble d'entraînement\n",
    "        _, predicted = torch.max(outputs, 1)  # Prend l'indice avec la plus grande probabilité\n",
    "        train_correct += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_accuracy = 100.0 * train_correct / total_train\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "\n",
    "            # Calcul de l'accuracy sur l'ensemble de validation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = 100.0 * val_correct / total_val\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    # Scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, '\n",
    "          f'Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, '\n",
    "          f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model_mnist.pt')\n",
    "        print(f'Meilleur modèle sauvegardé avec une perte de validation de {best_val_loss:.4f}')\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'Patience counter: {patience_counter}. Meilleure perte de validation: {best_val_loss:.4f}')\n",
    "        if patience_counter >= patience:\n",
    "            print('Early stopping triggered. Fin de l\\'entraînement.')\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Courbe d\\'entraînement et de validation')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Étape 12 : Charger le meilleur modèle et évaluer les performances\n",
    "model.load_state_dict(torch.load('best_model_mnist.pt'))\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Précision sur le jeu de validation : {100 * correct / total:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
